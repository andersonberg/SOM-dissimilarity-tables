%% M.Sc. Thesis
%% Author: Anderson Berg
%% CIn-UFPE

\chapter{Experimentos}

Para comparar os resultados dos grupos fornecidos pelos algoritmos, serão considerador um índice externo -- o índice de Rand corrigido ($CR$) \citep{Hubert85} -- como também o índice $F-measure$ \citep{Rijisbergen79} e a taxa de erro global de classificação (overall error rate of classification -- $OERC$) \citep{Breiman84}.

Seja $P = \{P_1, \dots, P_i, \dots, P_m\}$ a partição \textit{a priori} em $m$ classes e $Q = \{Q_1, \dots, Q_j, \dots, Q_K\}$ a partição em $K$ grupos dada pelo algoritmo de agrupamento. A matriz de confusão é dada abaixo:

\begin{table}[h!]
\caption{Matriz de Confusão}\label{t-0}
\begin{center}
%{\scriptsize
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{6}{|c|}{Clusters}
\\ \cline{2-7}
\multicolumn{1}{|c|}{Classes} & \multicolumn{1}{|c|}{$Q_1$} & \multicolumn{1}{|c|}{$\ldots$} & \multicolumn{1}{|c|}{$Q_j$} & \multicolumn{1}{|c|}{$\ldots$} & \multicolumn{1}{|c|}{$Q_K$} & \multicolumn{1}{|c|}{$\sum$}  \\ \hline
$P_1$	&$n_{11}$	&$\ldots$	&$n_{1j}$	&$\ldots$	&$n_{1K}$ &	$n_{1\bullet} = \sum_{j=1}^K n_{1j}$\\
$\vdots$	&$\vdots$	&$\hdots$	&$\vdots$	&$\hdots$	&$\vdots$ &	$\vdots$ \\
$P_i$	&$n_{i1}$	&$\ldots$	&$n_{ij}$	&$\ldots$	&$n_{iK}$ &	$n_{i\bullet} = \sum_{j=1}^K n_{ij}$ \\
$\vdots$	&$\vdots$	&$\ldots$	&$\vdots$	&$\ldots$	&$\vdots$ &	 \\
$P_m$	&$n_{m1}$	&$\ldots$	&$n_{mj}$	&$\ldots$	&$n_{mK}$ & $n_{m\bullet} = \sum_{j=1}^K n_{mj}$\\ \hline
$\sum$  & $n_{\bullet1} = \sum_{i=1}^m n_{i1}$ & $\ldots$ & $n_{\bullet j} = \sum_{i=1}^m n_{ij}$ &$\ldots$ & $n_{\bullet K} = \sum_{i=1}^m n_{iK}$ & $n=\sum_{i=1}^m \sum_{j=1}^K n_{ij}$\\ \hline
\end{tabular}
%}
\end{center}
\end{table}

O índice de Rand corrigido é:

\begin{equation} \label{eq:adjustedrand} CR =
\frac{\sum_{i=1}^m\sum_{j=1}^K {{n_{ij}}\choose{2}} -
{{n}\choose{2}}^{-1}\sum_{i=1}^m{{n_{i\bullet}}\choose{2}}\sum_{j=1}^K{{n_{\bullet j}}\choose{2}}}
{\frac{1}{2}[\sum_{i=1}^m{{n_{i\bullet}}\choose{2}}+\sum_{j=1}^K{{n_{\bullet j}}\choose{2}}]
-{{n}\choose{2}}^{-1}\sum_{i=1}^m{{n_{i\bullet}}\choose{2}}\sum_{j=1}^K{{n_{\bullet j}}\choose{2}}}
\end{equation}

\noindent onde ${{n}\choose{2}}=\frac{n(n-1)}{2}$ e $n_{ij}$ representa o número de objetos que estão na classe $P_i$ e no grupo $Q_j$; $n_{i\bullet}$ indica o número de objetos na classe $P_i$; $n_{\bullet j}$ indica o número de objetos no grupo $Q_j$; e $n$ é o número total de objetos na base de dados.

O índice \textit{CR} avalia o grau de combinação (semelhança) entre uma partição \textit{a priori} e uma partição fornecida por um algoritmo de agrupamento. Além disso, o índice \textit{CR} não é sensível ao número de classes nas partições ou à distribuição dos itens nos grupos. Finalmente, o índice $CR$ possui valores no intervalo [-1,1], onde 1 indica perfeita combinação entre as partições, enquanto que valores próximos a 0 (ou negativos) correspondem a combinação entre partições encontrada por acaso \citep{Milligan96}.

A tradicional medida $F-measure$ entre a classe $P_i \, (i=1,\ldots,m)$ e o grupo $Q_j \, (j=1,\ldots,K)$ é a média harmônica de \textit{precision} e \textit{recall}:

\begin{equation}
F-measure(P_i,Q_j) = 2 \, \frac{Precision(P_i,Q_j)\,Recall(P_i,Q_j) }{Precision(P_i,Q_j)+Recall(P_i,Q_j)}
\end{equation}

$Precision$ entre a classe $P_i \, (i=1,\ldots,m)$ e o grupo $Q_j \, (j=1,\ldots,K)$ é definido como a taxa entre o número de objetos que estão na classe $P_i$ e no grupo $Q_j$ e o número de objetos em $Q_j$:

\begin{equation}
Precision(P_i,Q_j) = \frac{n_{ij}}{n_{\bullet j}} = \frac{n_{ij}}{\sum_{i=1}^m n_{ij}}
\end{equation}

$Recall$ entre a classe $P_i \, (i=1,\ldots,m)$ e o grupo $Q_j \, (j=1,\ldots,K)$ é definido como a taxa entre o número de objetos que estão na classe $P_i$ e no grupo $Q_j$ e o número de objetos na classe $P_i$:

\begin{equation}
Recall(P_i,Q_j) = \frac{n_{ij}}{n_{i\bullet}} = \frac{n_{ij}}{\sum_{j=1}^K n_{ij}}
\end{equation}

$F-measure$ entre a partição \textit{a priori} $P = \{P_1, \dots, P_i, \dots, P_m\}$ e a partição $Q = \{Q_1, \dots, Q_j, \dots, Q_K\}$ fornecida pelo algoritmo de agrupamento é definido como:

\begin{equation} \label{eq:Fmeasure}
F-measure(P,Q) = \frac{1}{n} \sum_{i=1}^m n_{i\bullet} 
\begin{tabular}[t]{c}
max
$_{1\leq j \leq K}$
\end{tabular}
F-measure(P_i,Q_j)
\end{equation}

O índice $F-measure$ possui valores dentro do intervalo [0,1], onde o valor 1 indica perfeita combinação entra as partições.

Em problemas de classificação, cada grupo $Q_j$ é associado a uma classe \textit{a priori} $P_i$ e esta associação precisa ser interpretada como se a verdadeira classe \textit{a priori} seja $P_i$. Uma vez tomada esta decisão, para um dado objeto do grupo $Q_j$ a decisão é correta se a classe \textit{a priori} do objeto é $P_i$ e é um erro se a classe \textit{a priori} não é $P_i$. Para se obter uma taxa de erro de classificação (error rate of classification -- $ERC$) mínimo, precisa-se buscar uma regra de decisão que minimize a probabilidade de erro.

Seja $p(P_i/Q_j)$ a probabilidade \textit{a posteriori} de que um objeto pertença à classe $P_i$ quando é associado ao grupo $Q_j$. Seja $p(Q_j)$ a probabilidade de que o objeto pertença ao grupo $Q_j$. A função $p$ é conhecida como função de verossimilhança.

A estimativa da máxima probabilidade \textit{a posteriori} (maximum a posteriori probability -- MAP) é a moda da probabilidade \textit{a posteriori} $p(P_i/Q_j)$ e o índice da classe \textit{a priori} associada a esta moda é dada por:

\begin{equation}
MAP(Q_j) = \arg \max_{1\leq i \leq m}p(P_i/Q_j)
\end{equation}

A regra de decisão de Bayes para minimizar a probabilidade média de erro é selecionar a classe \textit{a priori} que maximiza a probabilidade \textit{a posteriori}. A taxa de erro de classificação $ERC(Q_j)$ do grupo $Q_j$ é igual a $1- p(P_{MAP(Q_j)}/Q_j)$ e a taxa de erro global de classificação $OERC$ é:

\begin{equation} 
OERC = \sum_{j=1}^K {p(Q_j)(1-p(P_{MAP(Q_j)}/Q_j))}
\end{equation}

Por exemplo,

\begin{equation}
p(P_{MAP(Q_j)}/Q_j)	 = \max_{1\leq i \leq m} \frac{n_{ij}}{n_{\bullet j}}.
\end{equation}

O índice $OERC$ mede a habilidade de um algoritmo de agrupamento de encontrar a classe \textit{a priori} presente em um conjunto de dados e é calculado por:

\begin{equation} \label{eq:oerc}
OERC = \sum_{j=1}^K \frac{n_{\bullet j}}{n} \, (1- \max_{1\leq i \leq m} n_{ij}/n_{\bullet j})=
1 - \frac{\sum_{j=1}^K \max_{1\leq i \leq m}{n_{ij}}}{n}
\end{equation}

A seguir, apresentamos as características principais de cada base de dados utilizada durante os experimentos, bem como os parâmetros selecionados para executar os algoritmos descritos neste trabalho. Além disso, discutimos os resultados dos experimentos realizados comparando os diferentes algoritmos entre si.

\section{Base de dados Íris}

Esta base de dados consiste em três tipos (classes) de íris de plantas: iris setosa, iris versicolour and iris virginica. As três classes possuem 50 instâncias (objetos) cada. Uma das classes é linearmente separada das outras duas, estas últimas não são linearmente separadas uma da outra. Cada objeto é descrito por quatro atributos de valores reais: (1) comprimento da sépala, (2) largura da sépala, (3) comprimento da pétala e (4) largura da pétala.

Os três algoritmos de agrupamento (SOM em lote baseado em uma única tabela de dissimilaridade, SOM em lote baseado em múltiplas tabelas de dissimilaridade com ponderação local e sua variante com ponderação global) foram aplicados às matrizes de dissimilaridade representando esta base de dados. No caso do SOM em lote original há somente uma matriz disponível, enquanto que, para os demais estão disponíveis múltiplas matrizes de dissimilaridade. Cada algoritmo foi executado 100 vezes e o melhor resultado foi selecionado de acordo com o critério de adequação. A topologia selecionada para o mapa nesta base de dados é formada por duas linhas e oito colunas (2x8) totalizando 16 grupos. O número de iterações escolhido foi de 100 ($N_{iter}=100$). Os experimentos de cada algoritmo foram executados com quatro valores diferentes para $T_{max}$: 6, 7, 9 e 16. Os valores de $T_{min}$ correspondentes foram fixados no valor de 0,3.

\subsubsection{Discussão dos Resultados}

A tabela \ref{iris_index} mostra os valores para os índices de Rand corrigido ($CR$), $F-measure$ e a Taxa de Erro Global de Classificação ($OERC$). Em cada linha dessa tabela, pode-se observar os valores dos índices para cada um dos diferentes valores de $T_{max}$.

\begin{table}[h!]
\begin{center}
\caption{Base de dados Íris: í­ndices $CR$, $F-measure$, e $OERC$} \label{iris_index}
%{\scriptsize
\begin{tabular}{|c|c|c|c|c|} \hline
 Índices & $T_{max}$ & B-SOM & AB-SOM & global AB-SOM \\ \hline
\multirow{4}{1.8cm}{$CR$} & 6 & 0.4017 & 0.4847 & 0.4599\\ 
 & 7 & 0.3999 & 0.5067 & 0.5157 \\ 
 & 9 & 0.3979 & 0.3978 & 0.4913 \\ 
 & 16 & 0.3958 & 0.4653 & 0.3889 \\ \hline
\multirow{4}{1.8cm}{$F-measure$} & 6 & 0.4931 & 0.5785 & 0.5501 \\
 & 7 & 0.5229 & 0.6071 & 0.5575  \\
 & 9 & 0.5394 & 0.5383 & 0.5490  \\
 & 16 & 0.5340 & 0.5742 & 0.5250 \\ \hline
\multirow{4}{1.8cm}{$OERC$} & 6 & 2.67\% & 4.00\% &  4.67\% \\ 
 & 7 &  2.67\% & 4.67\% & 4.00\% \\ 
 & 9 & 4.67\% & 3.33\% & 5.49\% \\ 
 & 16 & 2.00\% & 4.67\% & 3.33\% \\ \hline

\end{tabular}
%}
\end{center}
\end{table}

Para esta base de dados, o melhor desempenho foi apresentado pelo SOM em lote ponderado localmente (AB-SOM) e pelo SOM em lote original, nesta ordem. O pior desempenho foi apresentado pelo SOM em lote ponderado globalmente (global AB-SOM).

A tabela \ref{iris_matrices} mostra o resultado final dos pesos que medem a influência de cada matriz sobre a formação dos grupos. Nesta tabela pode-se observar quais matrizes tiveram maior e menor relevância geral para cada um dos algoritmos para o caso em que o valor de $T_{max} = 16$. A variável representando o comprimento da pétala obteve o maior grau de relevância para os dois algoritmos apresentados.

\begin{table}[h!]
\caption{Base Íris: Matrizes relevantes ($T_{max} = 16$)} \label{iris_matrices}
\begin{center}
%{\scriptsize
\begin{tabular}{|c|c|c|}
\hline
Modelo & Matriz mais importante & Matriz menos importante \\ \hline
AB-SOM & 3-comprimento da pétala & 1-comprimento da sépala \\ \hline
global AB-SOM & 3-comprimento da pétala & 2-largura da sépala \\ \hline
\end{tabular}
%}
\end{center}
\end{table}

A tabela \ref{iris_adapt_matrix} mostra a matriz de confusão para o algoritmo SOM em lote para múltiplas tabelas de dissimilaridade com ponderação local (AB-SOM) aplicado à base de dados íris, neste caso com $T_{max} = 6$. A classe com maior número de elementos pertencentes ao grupo é a representante deste grupo. Logo, é possível observar que existe uma estrutura inerente aos dados. Por exemplo, os primeiros dois grupos (0,0 e 0,1) representam a classe Iris versicolour, assim como o segundo grupo, na segunda linha (1,1). Semelhantemente, os últimos grupos no mapa (0,7 e 1,7) representam a classe Iris setosa, ilustrando que elementos semelhantes se posicionam e m grupos próximos.

\begin{table}[!h]
\caption{Base Íris: matriz de confusão do algoritmo AB-SOM para mútiplas tabelas de dissimilaridade ($T_{max} = 6$)}\label{iris_adapt_matrix}
\begin{center}
%{\scriptsize
\begin{tabular}{|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{3}{|c|}{Classes}
\\ \cline{2-4}
Grupos & 1-Iris setosa & 2-Iris versicolour & 3-Iris virginica \\ \hline
0,0 & 0 & 16 & 0 \\ \hline
0,1 & 0 & 12 & 0 \\ \hline
0,2 & 0 & 1 & 10 \\ \hline
0,3 & 0 & 4 & 0 \\ \hline
0,4 & 0 & 0 & 12 \\ \hline
0,5 & 0 & 0 & 3 \\ \hline
0,6 & 0 & 0 & 0 \\ \hline
0,7 & 38 & 0 & 0 \\ \hline \hline
1,0 & 0 & 2 & 10 \\ \hline
1,1 & 0 & 9 & 0 \\ \hline
1,2 & 0 & 3 & 0 \\ \hline
1,3 & 0 & 0 & 6 \\ \hline
1,4 & 0 & 0 & 4 \\ \hline
1,5 & 0 & 3 & 3 \\ \hline
1,6 & 0 & 0 & 2 \\ \hline
1,7 & 12 & 0 & 0 \\ \hline
\end{tabular}
%}
\end{center}
\end{table}

A tabela \ref{iris_absom_weight} mostra a matriz de pesos final para o algoritmo AB-SOM para múltiplas tabelas de dissimilaridade, com $T_{max} = 6$. Nesta tabela, os números em negrito possuem valor maior do que 1 e representam as matrizes mais relevantes na formação dos grupos de dados. Por exemplo, os pesos para as matrizes (3) comprimento da pétala e (4) largura da pétala possuem valores maiores do que as demais, denotando uma maior importância no momento em que os objetos são alocados a um determinado grupo.

\begin{table}[h!]
\caption{Base Íris: Matriz de pesos final do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 6$)}\label{iris_absom_weight}
\begin{center}
%{\scriptsize
\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{4}{|c|}{Matriz}
\\ \cline{2-5}
Grupos & 1-Sepal length & 2-Sepal width & 3-Petal length & 4-Petal width\\ \hline
0,0 & 0.5878 & 0.5075 & \textbf{2.1617} & \textbf{1.5507}\\ \hline
0,1 & 0.1438 & 0.7925 & \textbf{1.5381} & \textbf{5.7034}\\ \hline
0,2 & 0.1193 & \textbf{47.9332} & 0.5631 & 0.3104\\ \hline
0,3 & 0.7568 & 0.9139 & \textbf{1.7698} & 0.8169\\ \hline
0,4 & 0.3581 & 0.3508 & \textbf{3.3944} & \textbf{2.3451}\\ \hline
0,5 & \textbf{1.7980} & 0.2266 & \textbf{2.7677} & 0.8866\\ \hline
0,6 & \textbf{1.0037} & 0.3404 & \textbf{1.6919} & \textbf{1.7297}\\ \hline
0,7 & 0.2591 & 0.0672 & \textbf{5.2699} & \textbf{10.8944}\\ \hline
1,0 & 0.4403 & 0.3797 & \textbf{4.1288} & \textbf{1.4484}\\ \hline
1,1 & 0.2676 & 0.2180 & \textbf{4.7063} & \textbf{3.6428}\\ \hline
1,2 & 0.1780 & \textbf{2.1141} & \textbf{1.1214} & \textbf{2.3694}\\ \hline
1,3 & \textbf{1.7573} & 0.0686 & \textbf{3.2489} & \textbf{2.5531}\\ \hline
1,4 & 0.3215 & 0.1939 & \textbf{4.4941} & \textbf{3.5684}\\ \hline
1,5 & \textbf{1.4477} & 0.1896 & \textbf{1.0308} & \textbf{3.5350}\\ \hline
1,6 & \textbf{2.0289} & 0.7747 & 0.6483 & 0.9812\\ \hline
1,7 & 0.4077 & 0.1109 & \textbf{5.3766} & \textbf{4.1132}\\ \hline
\end{tabular}
%}
\end{center}
\end{table}



\section{Base de dados E.coli}

A base de dados E.coli contém informações sobre proteínas classificadas em oito classes. Existem 336 exemplos descritos por 6 atributos, onde um dos atributos é a classe. As classes e suas distribuições são as seguintes: cp (cytoplasm), 143 exemplos; im (inner membrane without signal sequence), 77 exemplos; pp (perisplasm), 52 exemplos; imU (inner membrane, uncleavable signal sequence), 35 exemplos; om (outer membrane), 20 exemplos; omL (outer membrane lipoprotein), 5 exemplos; imL (inner membrane lipoprotein), 2 exemplos; imS (inner membrane, cleavable signal sequence), 2 exemplos. Cada exemplos (objeto) é descrito por oito atributos.

Os três algoritmos de agrupamento (SOM em lote baseado em uma única tabela de dissimilaridade, SOM em lote baseado em múltiplas tabelas de dissimilaridade com ponderação local e sua variante com ponderação global) foram aplicados às matrizes de dissimilaridade representando esta base de dados. No caso do SOM em lote original há somente uma matriz disponível, enquanto que, para os demais estão disponíveis múltiplas matrizes de dissimilaridade. Cada algoritmo foi executado 100 vezes e o melhor resultado foi selecionado de acordo com o critério de adequação. A topologia selecionada para o mapa nesta base de dados é formada por três linhas e cinco colunas (3x5) totalizando 15 grupos. O número de iterações escolhido foi de 50 ($N_{iter}=50$). Os experimentos de cada algoritmo foram executados com quatro valores diferentes para $T_{max}$: 4; 4,5; 6 e 10. Os valores de $T_{min}$ correspondentes foram fixados no valor de 0,3.

\subsubsection{Discussão dos Resultados}

A tabela \ref{ecoli_index} mostra os valores do índice de Rand corrigido ($CR$), $F-measure$, e $OERC$ para cada um dos algoritmos. Em cada linha dessa tabela, pode-se observar os valores dos índices para cada um dos diferentes valores de $T_{max}$.

\begin{table}[h!]
\begin{center}
\caption{Base E.coli: índices $CR$, $F-measure$, e $OERC$} \label{ecoli_index}

\begin{tabular}{|c|c|c|c|c|} \hline
 Índices & $T_{max}$ & B-SOM & AB-SOM & global AB-SOM \\ \hline
\multirow{4}{1.8cm}{$CR$} & 4 & 0.3035 & 0.3213 & 0.2739 \\ 
 & 4.5 & 0.3462 & 0.2899 & 0.3165 \\ 
 & 6 & 0.3264 & 0.2867 & 0.3555 \\ 
 & 10 & 0.3303 & 0.2998 & 0.2925 \\ \hline
\multirow{4}{1.8cm}{$F-measure$} & 4 & 0.4473 & 0.4629 & 0.4082 \\
 & 4.5 & 0.5486 & 0.4153 & 0.4680 \\
 & 6 & 0.4631 & 0.4036 & 0.5265 \\
 & 10 & 0.5187 & 0.4385 & 0.4460 \\ \hline
\multirow{4}{1.8cm}{$OERC$} & 4 & 21.43\% & 17.56\% & 24.40\% \\ 
 & 4.5 & 16.37\% & 25.30\% & 20.54\% \\ 
 & 6 & 16.37\% & 24.11\% & 14.88\% \\ 
 & 10 & 15.77\% & 24.70\% & 24.40\% \\ \hline

\end{tabular}
\end{center}
\end{table}

A tabela \ref{ecoli_matrices} mostra as matrizes mais relevantes e menos relevantes para a definição dos grupos. As matrizes com maior relevância são aquelas que obtiveram maior peso no final da execução do algoritmo, as matrizes de menor relevâncias são as que obtiveram os menores pesos. Nesta tabela, pode-se observar as matrizes mais e menos importantes para cada algoritmo com $T_{max} = 4$.

\begin{table}[h!]
\caption{Base E.coli: Matrizes relevantes ($T_{max} = 4$)} \label{ecoli_matrices}
\begin{center}

\begin{tabular}{|c|c|c|}
\hline
Modelo & Matriz mais importante & Matriz menos importante \\ \hline
AB-SOM & 5 & 3\\ \hline
global AB-SOM & 4 & 3\\ \hline
\end{tabular}
\end{center}
\end{table}

A tabela \ref{ecoli_adapt_matrix} mostra a matriz de confusão para o algoritmo AB-SOM para múltiplas tabelas de dissimilaridade aplicado à base de dados, com $T_{max} = 10$. Da mesma forma que a base de dados anterior, pode-se buscar regiões na matriz (que representa o mapa) onde objetos de uma mesma classe são localizados. Por exemplo, os grupos 0,4; 1,2; 1,3; 1,4; 2,3 e 2,4 representam a classe 1.

A tabela \ref{ecoli_gl_absom_weight} apresenta a matriz de pesos final para o algoritmo AB-SOM com ponderação global para $T_{max} = 10$. Os pesos para este algoritmo são os mesmos para todos os grupos, porém diferentes de uma matriz para outra. Nesta tabela, os números em negrito indicam pesos com valor maior do que 1 e representam matrizes com maior relevância na formação de cada grupo. Por exemplo, os pesos das matrizes 4 e 5 possuem valores maiores do que as demais matrizes, indicando maior influência no momento em que os objetos são alocados a um determinado grupo.


\begin{table}[h!]
\caption{Base E.coli: matriz de confusão do algoritmo AB-SOM global para múltiplas tabelas de dissimilaridade ($T_{max} = 10$)}\label{ecoli_adapt_matrix}
\begin{center}

\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{8}{|c|}{Classes}
\\ \cline{2-9}
Grupos & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 \\ \hline
0,0 & 0 & 18 & 0 & 0 & 16 & 1 & 0 & 0 \\ \hline
0,1 & 0 & 10 & 0 & 1 & 24 & 0 & 0 & 0 \\ \hline
0,2 & 0 & 6 & 1 & 0 & 17 & 1 & 0 & 0 \\ \hline
0,3 & 6 & 0 & 0 & 0 & 1 & 4 & 0 & 0 \\ \hline
0,4 & 22 & 0 & 0 & 0 & 2 & 0 & 0 & 0 \\ \hline \hline
1,0 & 1 & 1 & 0 & 1 & 6 & 5 & 5 & 2 \\ \hline
1,1 & 0 & 0 & 0 & 0 & 10 & 0 & 0 & 0 \\ \hline
1,2 & 10 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\ \hline
1,3 & 15 & 0 & 0 & 0 & 0 & 1 & 0 & 0 \\ \hline
1,4 & 22 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ \hline \hline
2,0 & 2 & 0 & 1 & 0 & 0 & 29 & 0 & 9 \\ \hline
2,1 & 0 & 0 & 0 & 0 & 0 & 10 & 0 & 9 \\ \hline
2,2 & 6 & 0 & 0 & 0 & 1 & 0 & 0 & 0 \\ \hline
2,3 & 25 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ \hline
2,4 & 34 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\caption{Base E.coli: Matriz de pesos final do algoritmo AB-SOM global para múltiplas tabelas de dissimilaridade ($T_{max} = 10$)}\label{ecoli_gl_absom_weight}
\begin{center}

\begin{tabular}{|c|c|c|c|c|}
\hline
\multicolumn{5}{|c|}{Matriz}\\ \cline{1-5}
1 & 2 & 3 & 4 & 5\\ \hline
0.7636 & 0.7101 & 0.4876 & \textbf{2.1144} & \textbf{1.7887}\\ \hline

\end{tabular}

\end{center}
\end{table}



\section{Base de dados Thyroid}

Esta base de dados consiste em três classes relativas ao estado da glândula tiroide: normal, hipertiroidismo e hipotiroidismo. As classes (1, 2 e 3) têm 150, 35 e 30 instâncias, respectivamente. Cada objeto é descrito por cinco atributos de valores reais: 1) T3-resin uptake test, (2) total serum thyroxin, (3) total serum triiodothyronine, (4) basal thyroid-stimulating hormone (TSH) e (5) maximal absolute difference in TSH value.


Os três algoritmos de agrupamento (SOM em lote baseado em uma única tabela de dissimilaridade, SOM em lote baseado em múltiplas tabelas de dissimilaridade com ponderação local e sua variante com ponderação global) foram aplicados às matrizes de dissimilaridade representando esta base de dados. No caso do SOM em lote original há somente uma matriz disponível, enquanto que, para os demais estão disponíveis múltiplas matrizes de dissimilaridade. Cada algoritmo foi executado 100 vezes e o melhor resultado foi selecionado de acordo com o critério de adequação. A topologia selecionada para o mapa nesta base de dados é formada por três linhas e cinco colunas (3x5) totalizando 15 grupos. O número de iterações escolhido foi de 50 ($N_{iter}=50$). Os experimentos de cada algoritmo foram executados com quatro valores diferentes para $T_{max}$: 4; 4,5; 6 e 10. Os valores de $T_{min}$ correspondentes foram fixados no valor de 0,3.

\subsubsection{Discussão dos Resultados}

A tabela \ref{thyroid_index} mostra os valores para os índices de Rand corrigido ($CR$), $F-measure$ e a Taxa de Erro Global de Classificação ($OERC$) obtidos para cada um dos algoritmos. Em cada linha dessa tabela, pode-se observar os valores dos índices para cada um dos diferentes valores de $T_{max}$. Para esta base, o melhor desempenho global foi apresentado pelos algoritmos AB-SOM com ponderação global and AB-SOM com ponderação local, nesta ordem.

\begin{table}[h!]
\begin{center}
\caption{Base de dados Thyroid: índices $CR$, $F-measure$ e $OERC$} \label{thyroid_index}
\begin{tabular}{|c|c|c|c|c|} \hline
 Índices & $T_{max}$ & B-SOM & AB-SOM & AB-SOM global\\ \hline
\multirow{4}{1.8cm}{$CR$} & 4 & 0.3662 & 0.4539 & 0.5700 \\
 & 5 & 0.3642 & 0.3689 & 0.3604 \\ 
 & 6 & 0.2618 & 0.3183 & 0.5882 \\ 
 & 10 & 0.3784 & 0.3660 & 0.3654 \\ \hline
\multirow{4}{1.8cm}{$F-measure$} & 4 & 0.4961 & 0.5841 & 0.5978 \\
 & 5 & 0.4870 & 0.4788 & 0.4678 \\
 & 6 & 0.4019 & 0.4850 & 0.6401 \\
 & 10 & 0.5023 & 0.5048 & 0.4885 \\ \hline
\multirow{4}{1.8cm}{$OERC$} & 4 & 9.77\% & 3.25\% & 4.65\% \\ 
 & 5 & 9.30\% & 5.58\% & 4.19\% \\ 
 & 6 & 11.16\% & 4.19\% & 7.44\% \\ 
 & 10 & 9.30\% & 3.72\% & 5.12\% \\ \hline
\end{tabular}
\end{center}
\end{table}

A tabela \ref{thyroid_matrices} mostra o resultado final dos pesos que medem a influência de cada matriz sobre a formação dos grupos. Nesta tabela pode-se observar quais matrizes tiveram maior e menor relevância geral para cada um dos algoritmos para o caso em que o valor de $T_{max} = 4$. A matriz representando o atributo TSH apresentou o peso com maior valor para o algoritmo AB-SOM com ponderação local, indicando maior influência na formação dos grupos durante a execução deste algoritmo. Para o algoritmo AB-SOM com ponderação global, o mesmo comportamento pode ser observado pela matriz representando o atributo \textit{maximal absolute difference}.

\begin{table}[h!]
\caption{Base de dados Thyroid: Matrizes ($T_{max} = 4$)} \label{thyroid_matrices}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Modelo & Matriz mais importante & Matriz menos importante \\ \hline
AB-SOM & 4-TSH & 1-T3-resin uptake test\\ \hline
global AB-SOM & 5-maximal absolute difference in TSH & 1-T3-resin uptake test\\ \hline
\end{tabular}
\end{center}
\end{table}

A tabela \ref{thy_adapt_matrix} apresenta a matriz de confusão da variante com ponderação local do algoritmo AB-SOM. A matriz de confusão mostra a distribuição das classes dentro dos grupos formados pelo algoritmo, desta forma é possível perceber regiões de grupos próximos onde há predominância de objetos de uma mesma classe. Por exemplo, os grupos 1,0; 1,1; 2,0 e 2,1 são formados por objetos, em sua maioria, da classe 1.

A tabela \ref{thy_absom_weight} apresenta a matriz de pesos final da variante com ponderação local do algoritmo AB-SOM. Nesta tabela pode-se perceber que as matrizes 4 (\textit{basal thyroid-stimulating hormone (TSH)}) e 5 (\textit{maximal absolute difference in TSH value}) obtiveram os maiores pesos, denotando maior relevância na formação dos grupos.

\begin{table}[h!]
\caption{Base Thyroid: matriz de confusão do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 4$)}\label{thy_adapt_matrix}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{3}{|c|}{Classes}
\\ \cline{2-4}
Grupos & 1 & 2 & 3 \\ \hline
0,0 & 0 & 27 & 0 \\ \hline
0,1 & 0 & 4 & 0 \\ \hline
0,2 & 1 & 0 & 0 \\ \hline
0,3 & 0 & 0 & 3 \\ \hline
0,4 & 0 & 0 & 10 \\ \hline \hline
1,0 & 21 & 1 & 0 \\ \hline
1,1 & 16 & 0 & 0 \\ \hline
1,2 & 0 & 3 & 0 \\ \hline
1,3 & 1 & 0 & 2 \\ \hline
1,4 & 0 & 0 & 1 \\ \hline \hline
2,0 & 53 & 0 & 1 \\ \hline
2,1 & 55 & 0 & 1 \\ \hline
2,2 & 3 & 0 & 3 \\ \hline
2,3 & 0 & 0 & 5 \\ \hline
2,4 & 0 & 0 & 4 \\ \hline
\end{tabular}
\end{center}
\end{table}


\begin{table}[h!]
\caption{Base Thyroid: Matriz de pesos final do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 4$)}\label{thy_absom_weight}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{5}{|c|}{Matriz}
\\ \cline{2-6}
Grupos & 1 & 2 & 3 & 4 & 5 \\ \hline
0,0 & 0.0664 & 0.1232 & 0.0416 & \textbf{24.5994} & \textbf{119.3779}\\ \hline
0,1 & 0.1721 & 0.0895 & 0.1687 & \textbf{33.7149} & \textbf{11.4190}\\ \hline
0,2 & 0.4323 & 0.3025 & \textbf{3.1604} & \textbf{3.8924} & 0.6216\\ \hline
0,3 & 0.3471 & \textbf{3.1358} & \textbf{1.1614} & \textbf{3.6163} & 0.2188\\ \hline
0,4 & 0.6744 & \textbf{3.3249} & \textbf{3.3112} & 0.0999 & \textbf{1.3487}\\ \hline
1,0 & 0.0594 & 0.6714 & 0.4313 & \textbf{21.1315} & \textbf{2.7514}\\ \hline
1,1 & 0.3278 & 0.2343 & 0.3235 & \textbf{8.5997} & \textbf{4.6795}\\ \hline
1,2 & 0.2886 & 0.0904 & 0.4556 & \textbf{34.0884} & 2.4665\\ \hline
1,3 & \textbf{2.5386} & \textbf{1.2595} & \textbf{1.1266} & 0.7627 & 0.3640\\ \hline
1,4 & 0.7004 & \textbf{2.4398} & \textbf{10.0863} & 0.1071 & 0.5420\\ \hline
2,0 & 0.1404 & 0.3898 & 0.5969 & \textbf{13.0529} & \textbf{2.3447}\\ \hline
2,1 & 0.2506 & 0.2350 & 0.6867 & \textbf{7.2315} & \textbf{3.4204}\\ \hline
2,2 & 0.7958 & 0.6775 & \textbf{3.3742} & \textbf{2.4085} & 0.2282\\ \hline
2,3 & \textbf{4.8434} & \textbf{2.3485} & \textbf{1.2337} & 0.6914 & 0.1031\\ \hline
2,4 & \textbf{1.5312} & \textbf{7.3742} & \textbf{7.5345} & 0.0125 & 0.9376\\ \hline
\end{tabular}
\end{center}
\end{table}


\section{Base de dados Wine}

Esta base de dados consiste em três tipos (classes) de vinhos, produzidos na mesma região da Itália, porém derivados de três diferentes cultivos. As classes (1, 2, e 3) possuem 59, 71 e 48 exemplos, respectivamente. Cada vinho é descrito por 13 atributos de valores reais representando as quantidades de 13 componentes encontrados em cada um dos três tipos de vinho. Estes atributos são: (1) alcohol; (2) malic acid; (3) ash; (4) alkalinity of ash; (5) magnesium; (6) total phenols; (7) flavonoids; (8) non-flavonoid phenols; (9) proanthocyanins; (10) color intensity; (11) hue; (12) OD280/OD315 of diluted wines; e (13) proline.

Os três algoritmos de agrupamento (SOM em lote baseado em uma única tabela de dissimilaridade, SOM em lote baseado em múltiplas tabelas de dissimilaridade com ponderação local e sua variante com ponderação global) foram aplicados às matrizes de dissimilaridade representando esta base de dados. No caso do SOM em lote original há somente uma matriz disponível, enquanto que, para os demais estão disponíveis múltiplas matrizes de dissimilaridade. Cada algoritmo foi executado 50 vezes e o melhor resultado foi selecionado de acordo com o critério de adequação. A topologia selecionada para o mapa nesta base de dados é formada por três linhas e cinco colunas (3x5) totalizando 15 grupos. O número de iterações escolhido foi de 50 ($N_{iter}=50$). Os experimentos de cada algoritmo foram executados com quatro valores diferentes para $T_{max}$: 4, 5, 6 e 10. Os valores de $T_{min}$ correspondentes foram fixados no valor de 0,3.

\subsection{Discussão dos Resultados}

A tabela \ref{wine_index} mostra os valores para os índices de Rand corrigido ($CR$), $F-measure$ e a Taxa de Erro Global de Classificação ($OERC$) obtidos para cada um dos algoritmos. Em cada linha dessa tabela, pode-se observar os valores dos índices para cada um dos diferentes valores de $T_{max}$. Para esta base, o melhor desempenho global foi apresentado pelos algoritmos AB-SOM com ponderação local and AB-SOM com ponderação global, nesta ordem. O SOM em lote original obteve o pior desempenho global nos índices.

A tabela \ref{wine_matrices} mostra o resultado final dos pesos que medem a influência de cada matriz sobre a formação dos grupos. Nesta tabela pode-se observar quais matrizes tiveram maior e menor relevância geral para cada um dos algoritmos para o caso em que o valor de $T_{max} = 4$. A matriz 2 apresentou o peso com maior valor para o algoritmo AB-SOM com ponderação local, indicando maior influência na formação dos grupos durante a execução deste algoritmo. Para o algoritmo AB-SOM com ponderação global, o mesmo comportamento pode ser observado pela matriz 7. Em ambos os algoritmos a matriz menos relevante foi a matriz 3.

A tabela \ref{wine_adapt_matrix} apresenta a matriz de confusão da variante com ponderação local do algoritmo AB-SOM. A matriz de confusão mostra a distribuição das classes dentro dos grupos formados pelo algoritmo, desta forma é possível perceber regiões de grupos próximos onde há predominância de objetos de uma mesma classe. Por exemplo, os grupos 0,0; 0,1; 0,1; 1,0 ; 1,1 e 1,2 são formados por objetos, em sua maioria, da classe 2.

A tabela \ref{wine_absom_weight} apresenta a matriz de pesos final da variante com ponderação local do algoritmo AB-SOM.

\begin{table}[h!]
\begin{center}
\caption{Base de dados Wine: índices $CR$, $F-measure$ e $OERC$} \label{wine_index}
\begin{tabular}{|c|c|c|c|c|c|c|} \hline
 Índices & $T_{max}$ & B-SOM & AB-SOM & global AB-SOM \\ \hline
\multirow{4}{1.8cm}{$CR$} & 4 & 0.2775 & 0.3560 & 0.3498 \\
 & 5 & 0.2857 & 0.3449 & 0.3248 \\ 
 & 6 & 0.2967 & 0.3589 & 0.3489 \\ 
 & 10 & 0.2940 & 0.3773 & 0.3339 \\ \hline
\multirow{4}{1.8cm}{$F-measure$} & 4 & 0.4163 & 0.4897 & 0.4737 \\
 & 5 & 0.4286 & 0.4735 & 0.4357 \\
 & 6 & 0.4343 & 0.5245 & 0.4801 \\
 & 10 & 0.4427 & 0.5332 & 0.4637 \\ \hline
\multirow{4}{1.8cm}{$OERC$} & 4 & 26.40\% & 7.30\% & 2.25\% \\ 
 & 5 & 26.97\% & 3.37\% & 4.49\% \\ 
 & 6 & 26.97\% & 4.49\% & 5.06\% \\ 
 & 10 & 26.97\% & 6.17\% & 6.74\% \\ \hline
\end{tabular}
\end{center}
\end{table}


\begin{table}[h!]
\caption{Base de dados Wine: Matrizes relevantes $T_{max} = 4$} \label{wine_matrices}
\begin{center}

\begin{tabular}{|c|c|c|}
\hline
Modelo & Matriz mais importante & Matriz menos importante \\ \hline
AB-SOM & 2 & 3\\ \hline
global AB-SOM & 7 & 3\\ \hline
\end{tabular}

\end{center}
\end{table}

\begin{table}[h!]
\caption{Base Wine: matriz de confusão do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 4$)}\label{wine_adapt_matrix}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{3}{|c|}{Classes}
\\ \cline{2-4}
Grupos & 1 & 2 & 3 \\ \hline
0,0 & 0 & 17 & 0 \\ \hline
0,1 & 0 & 13 & 0 \\ \hline
0,2 & 0 & 4 & 0 \\ \hline
0,3 & 14 & 2 & 0 \\ \hline
0,4 & 13 & 3 & 0 \\ \hline \hline
1,0 & 0 & 8 & 0 \\ \hline
1,1 & 0 & 5 & 0 \\ \hline
1,2 & 0 & 3 & 0 \\ \hline
1,3 & 4 & 0 & 0 \\ \hline
1,4 & 16 & 0 & 0 \\ \hline \hline
2,0 & 0 & 0 & 27 \\ \hline
2,1 & 0 & 4 & 21 \\ \hline
2,2 & 0 & 6 & 0 \\ \hline
2,3 & 4 & 6 & 0 \\ \hline
2,4 & 8 & 0 & 0 \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\caption{Base Wine: Matriz de pesos final do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 4$)}\label{wine_absom_weight}
\begin{center}
\scriptsize{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{13}{|c|}{Matriz}
\\ \cline{2-14}
Grupos & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13\\ \hline
0,0 & 1.0091 & 0.2418 & 0.5776 & \textbf{1.2869} & \textbf{1.0148} & \textbf{2.2689} & \textbf{2.1911} & 0.5327 &  0.1577 & \textbf{8.5170} & 0.1886 & \textbf{1.2842} & 6.3060 \\ \hline
0,1 & \textbf{2.0952} & \textbf{3.0960} & 0.2255 & 0.2106 & \textbf{1.2340} & 0.8592 & \textbf{1.2570} & 0.7623 & 0.6877 & \textbf{1.8400} & 0.8322 & 0.4789 & \textbf{6.3369}\\ \hline
0,2 & 0.7646 & \textbf{22.5494} & 0.3384 & 0.5242 & 0.5694 & 0.7708 & 0.2690 & 0.9311 & \textbf{1.3197} & \textbf{2.0367} & \textbf{1.1857} & \textbf{1.3798} & 0.6761\\ \hline
0,3 & 0.8196 & \textbf{7.8194} & 0.5720 & 0.1287 & 0.2032 & \textbf{1.8406} & \textbf{3.5010} & \textbf{2.0590} & 0.8395 & \textbf{1.2363} & 0.7589 & \textbf{1.9563} & 0.5102\\ \hline
0,4 & 0.3127 & 0.2991 & 0.1518 & 0.3934 & 0.8294 & \textbf{2.2293} & \textbf{1.2320} & \textbf{1.1951} & \textbf{1.1951} & \textbf{2.3507} & \textbf{3.1830} & 5.2633 & 1.2622\\ \hline
1,0 & 0.4036 & 0.1882 & \textbf{1.8297} & \textbf{2.4907} & \textbf{2.8641} & 0.5187 & \textbf{3.4603} & 0.2615 & 0.9836 & \textbf{1.3417} & \textbf{1.1557} & 0.6300 & \textbf{2.2362}\\ \hline
1,1 & \textbf{2.8292} & 0.1368 & 0.2785 & 0.2677 & 0.2585 & \textbf{3.1064} & \textbf{2.3869} & \textbf{1.1112} & \textbf{1.6055} & \textbf{3.5324} & 0.6597 & \textbf{2.4387} & \textbf{1.7830}\\ \hline
1,2 & \textbf{9.8638} & \textbf{2.4959} & 0.5399 & 0.4135 & 0.1789 & 0.8419 & \textbf{1.5752} & 0.2981 & 0.6333 & \textbf{4.2140} & 0.7668 & 0.6312 & \textbf{1.9912}\\ \hline
1,3 & \textbf{1.4122} & \textbf{2.6194} & \textbf{1.1263} & \textbf{1.0065} & 0.4545 & \textbf{1.5549} & \textbf{1.9557} & \textbf{4.3371} & 0.1168 & 0.7453 & 0.3839 & 0.8804 & \textbf{1.3518}\\ \hline
1,4 & \textbf{1.1598} & \textbf{7.1409} & 0.7875 & 0.2511 & 0.6866 & 0.7305 & \textbf{2.5217} & 0.7350 & 0.5438 & \textbf{1.2208} & 0.8783 & \textbf{2.2542} & 0.4999\\ \hline
2,0 & 0.8860 & 0.3491 & 0.6620 & 0.7487 & 0.3790 & 0.9119 & 3.9119 & 0.4539 & 0.6751 & 0.6581 & \textbf{1.4272} & \textbf{6.4068} & \textbf{2.6159}\\ \hline
2,1 & \textbf{1.1684} & 0.3561 & 0.7714 & 0.5439 & 0.5684 & 0.9285 & \textbf{3.4554} & 0.3391 & \textbf{2.2713} & \textbf{1.4523} & 0.8220 & \textbf{1.7653} & \textbf{1.9353}\\ \hline
2,2 & \textbf{2.9161} & 0.6551 & 0.4344 & 0.8233 & 0.4047 & \textbf{4.7123} & \textbf{1.7193} & 0.2413 & 0.7783 & \textbf{6.6365} & 0.1965 & \textbf{2.3237} & 0.7848\\ \hline
2,3 & 0.4143 & \textbf{2.9362} & 0.1725 & 0.6155 & 0.9462 & \textbf{2.0611} & \textbf{1.5180} & \textbf{2.4741} & 0.5845 & \textbf{2.6926} & \textbf{4.5711} & 0.8081 & 0.1817\\ \hline
2,4 & \textbf{2.0394} & \textbf{14.9034} & 0.1463 & 0.2290 & 0.2613 & \textbf{1.1660} & \textbf{2.5287} & 0.3144 & 0.3044 & 0.8857 & \textbf{2.3069} & \textbf{7.2819} & 0.8949\\ \hline
\end{tabular}
}
\end{center}
\end{table}

\section{Base de dados Wine Quality}

A base de dados Wine quality consiste em duas bases relacionadas às variantes tinto e branco do vinho português "Vinho Verde" \cite{Cortez2009}. Somente a variante de vinho tinto foi considerado para estes experimentos. Existem 1599 exemplos, cada um é descrito por 11 atributos mais o atributo de classificação. Esta classificação é baseada em dados sensoriais (média de, pelo menos, 3 avaliações feitas por especialistas em vinho). Cada especialista classifica as qualidade de vinho entre 0 (muito ruim) e 10 (excelente). Neste exemplo, as classificações de vinho tinto são: (1) fixed acidity, (2) volatile acidity, (3) citric acid, (4) residual sugar, (5) chlorides, (6) free sulfur dioxide, (7) total sulfur dioxide, (8) density, (9) pH, (10) sulphates e (11) alcohol.

Os três algoritmos de agrupamento (SOM em lote baseado em uma única tabela de dissimilaridade, SOM em lote baseado em múltiplas tabelas de dissimilaridade com ponderação local e sua variante com ponderação global) foram aplicados às matrizes de dissimilaridade representando esta base de dados. No caso do SOM em lote original há somente uma matriz disponível, enquanto que, para os demais estão disponíveis múltiplas matrizes de dissimilaridade. Cada algoritmo foi executado 30 vezes e o melhor resultado foi selecionado de acordo com o critério de adequação. A topologia selecionada para o mapa nesta base de dados é formada por três linhas e dez colunas (3x10) totalizando 30 grupos. O número de iterações escolhido foi de 30 ($N_{iter}=30$). Os experimentos de cada algoritmo foram executados com quatro valores diferentes para $T_{max}$: 8, 9, 12 e 20. Os valores de $T_{min}$ correspondentes foram fixados no valor de 0,3.

\subsubsection{Discussão dos Resultados}

A tabela \ref{winered_index} mostra os valores obtidos por todos os algoritmos para os índices $CR$, $F-measure$ e $OERC$, considerando diferentes valores para $T_{max}$. O melhor desempenho global foi apresentado pelo algoritmo AB-SOM baseado em múltiplas tabelas de dissimilaridade com ponderação local.

A tabela \ref{winered_matrices} mostra o resultado final dos pesos que medem a influência de cada matriz sobre a formação dos grupos. Nesta tabela pode-se observar quais matrizes tiveram maior e menor relevância geral para cada um dos algoritmos para o caso em que o valor de $T_{max} = 12$. A matriz 12 apresentou o peso com maior valor para o algoritmo AB-SOM com ponderação local, indicando maior influência na formação dos grupos durante a execução deste algoritmo. Para o algoritmo AB-SOM com ponderação global, o mesmo comportamento pode ser observado pela matriz 9.

\begin{table}[h!]
\begin{center}
\caption{Base Wine Quality: índices $CR$, $F-measure$ e $OERC$} \label{winered_index}
%{\scriptsize
\begin{tabular}{|c|c|c|c|c|c|c|} \hline
 Indexes & $T_{max}$ & B-SOM & AB-SOM & global AB-SOM\\ \hline
\multirow{4}{1.8cm}{$CR$} & 8 & 0.1175 & 0.3777 & 0.1234 \\
 & 9 & 0.1239 & 0.3631 & 0.1163 \\ 
 & 12 & 0.1249 & 0.3185 & 0.1300 \\ 
 & 20 & 0.1432 & 0.3549 & 0.1143 \\ \hline
\multirow{4}{1.8cm}{$F-measure$} & 8 & 0.1850 & 0.4464 & 0.2465 \\
 & 9 & 0.1940 & 0.4507 & 0.2297 \\
 & 12 & 0.2068 & 0.4252 & 0.2290 \\
 & 20 & 0.2125 & 0.4363 & 0.2227 \\ \hline
\multirow{4}{1.8cm}{$OERC$} & 8 & 47.90\% & 44.00\% & 48.27\% \\ 
 & 9 & 50.03\% & 43.94\% & 48.14\% \\ 
 & 12 & 49.21\% & 43.69\% & 46.77\% \\
 & 20 & 49.15\%	& 43.06\% & 47.27\% \\ \hline
\end{tabular}
%}
\end{center}
\end{table}

\begin{table}[h!]
\caption{Wine Quality data set: Relevance matrices $T_{max} = 12$} \label{winered_matrices}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Model & Most important matrix & Less important matrix \\ \hline
AB-SOM & 12 & 5\\ \hline
global AB-SOM & 9 & 12\\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\caption{Base Wine Quality: matriz de confusão do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 12$)}\label{winered_adapt_matrix}
\begin{center}
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{6}{|c|}{Classes}
\\ \cline{2-7}
Grupos & 3 & 4 & 5 & 6 & 7 & 8\\ \hline
0,0 & 0 & 0 & 6 & 6 & 2 & 0\\ \hline
0,1 & 0 & 1 & 0 & 1 & 0 & 0\\ \hline
0,2 & 3 & 13 & 162 & 208 & 46 & 1\\ \hline
0,3 & 0 & 0 & 0 & 3 & 0 & 0\\ \hline
0,4 & 1 & 11 & 35 & 124 & 46 & 7\\ \hline \hline
1,0 & 0 & 0 & 3 & 3 & 0 & 0\\ \hline
1,1 & 0 & 0 & 1 & 0 & 0 & 0\\ \hline
1,2 & 0 & 1 & 122 & 33 & 0 & 0\\ \hline
1,3 & 0 & 4 & 15 & 33 & 24 & 2\\ \hline
1,4 & 0 & 0 & 6 & 12 & 7 & 0\\ \hline \hline
2,0 & 0 & 0 & 2 & 2 & 0 & 0\\ \hline
2,1 & 1 & 0 & 10 & 4 & 0 & 0\\ \hline
2,2 & 4 & 22 & 304 & 140 & 9 & 1\\ \hline
2,3 & 0 & 0 & 11 & 50 & 54 & 6\\ \hline
2,4 & 1 & 1 & 4 & 14 & 10 & 1\\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\caption{Base Wine Quality: Matriz de pesos final do algoritmo AB-SOM para múltiplas tabelas de dissimilaridade ($T_{max} = 12$)}\label{winered_absom_weight}
\begin{center}
\scriptsize{
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{1}{|c|}{} &
\multicolumn{13}{|c|}{Matriz}
\\ \cline{2-14}
Grupos & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & 13\\ \hline
0,0 & 1.0091 & 0.2418 & 0.5776 & \textbf{1.2869} & \textbf{1.0148} & \textbf{2.2689} & \textbf{2.1911} & 0.5327 &  0.1577 & \textbf{8.5170} & 0.1886 & \textbf{1.2842} & 6.3060 \\ \hline
0,1 & \textbf{2.0952} & \textbf{3.0960} & 0.2255 & 0.2106 & \textbf{1.2340} & 0.8592 & \textbf{1.2570} & 0.7623 & 0.6877 & \textbf{1.8400} & 0.8322 & 0.4789 & \textbf{6.3369}\\ \hline
0,2 & 0.7646 & \textbf{22.5494} & 0.3384 & 0.5242 & 0.5694 & 0.7708 & 0.2690 & 0.9311 & \textbf{1.3197} & \textbf{2.0367} & \textbf{1.1857} & \textbf{1.3798} & 0.6761\\ \hline
0,3 & 0.8196 & \textbf{7.8194} & 0.5720 & 0.1287 & 0.2032 & \textbf{1.8406} & \textbf{3.5010} & \textbf{2.0590} & 0.8395 & \textbf{1.2363} & 0.7589 & \textbf{1.9563} & 0.5102\\ \hline
0,4 & 0.3127 & 0.2991 & 0.1518 & 0.3934 & 0.8294 & \textbf{2.2293} & \textbf{1.2320} & \textbf{1.1951} & \textbf{1.1951} & \textbf{2.3507} & \textbf{3.1830} & 5.2633 & 1.2622\\ \hline
1,0 & 0.4036 & 0.1882 & \textbf{1.8297} & \textbf{2.4907} & \textbf{2.8641} & 0.5187 & \textbf{3.4603} & 0.2615 & 0.9836 & \textbf{1.3417} & \textbf{1.1557} & 0.6300 & \textbf{2.2362}\\ \hline
1,1 & \textbf{2.8292} & 0.1368 & 0.2785 & 0.2677 & 0.2585 & \textbf{3.1064} & \textbf{2.3869} & \textbf{1.1112} & \textbf{1.6055} & \textbf{3.5324} & 0.6597 & \textbf{2.4387} & \textbf{1.7830}\\ \hline
1,2 & \textbf{9.8638} & \textbf{2.4959} & 0.5399 & 0.4135 & 0.1789 & 0.8419 & \textbf{1.5752} & 0.2981 & 0.6333 & \textbf{4.2140} & 0.7668 & 0.6312 & \textbf{1.9912}\\ \hline
1,3 & \textbf{1.4122} & \textbf{2.6194} & \textbf{1.1263} & \textbf{1.0065} & 0.4545 & \textbf{1.5549} & \textbf{1.9557} & \textbf{4.3371} & 0.1168 & 0.7453 & 0.3839 & 0.8804 & \textbf{1.3518}\\ \hline
1,4 & \textbf{1.1598} & \textbf{7.1409} & 0.7875 & 0.2511 & 0.6866 & 0.7305 & \textbf{2.5217} & 0.7350 & 0.5438 & \textbf{1.2208} & 0.8783 & \textbf{2.2542} & 0.4999\\ \hline
2,0 & 0.8860 & 0.3491 & 0.6620 & 0.7487 & 0.3790 & 0.9119 & 3.9119 & 0.4539 & 0.6751 & 0.6581 & \textbf{1.4272} & \textbf{6.4068} & \textbf{2.6159}\\ \hline
2,1 & \textbf{1.1684} & 0.3561 & 0.7714 & 0.5439 & 0.5684 & 0.9285 & \textbf{3.4554} & 0.3391 & \textbf{2.2713} & \textbf{1.4523} & 0.8220 & \textbf{1.7653} & \textbf{1.9353}\\ \hline
2,2 & \textbf{2.9161} & 0.6551 & 0.4344 & 0.8233 & 0.4047 & \textbf{4.7123} & \textbf{1.7193} & 0.2413 & 0.7783 & \textbf{6.6365} & 0.1965 & \textbf{2.3237} & 0.7848\\ \hline
2,3 & 0.4143 & \textbf{2.9362} & 0.1725 & 0.6155 & 0.9462 & \textbf{2.0611} & \textbf{1.5180} & \textbf{2.4741} & 0.5845 & \textbf{2.6926} & \textbf{4.5711} & 0.8081 & 0.1817\\ \hline
2,4 & \textbf{2.0394} & \textbf{14.9034} & 0.1463 & 0.2290 & 0.2613 & \textbf{1.1660} & \textbf{2.5287} & 0.3144 & 0.3044 & 0.8857 & \textbf{2.3069} & \textbf{7.2819} & 0.8949\\ \hline
\end{tabular}
}
\end{center}
\end{table}

\section{Base de dados Phoneme}

\section{Base de dados Multiple Features}

Esta base consiste em características de numerais ('0' -- '9') escritos à mão extraídos de uma coleção de mapas de utilidade holandeses. 200 padrões por classe (de um total de 2000 padrões) foram digitalizados em imagens binárias. Os padrões são divididos em dez classes representando cada uma dos numerais escritos à mão de zero a nove. Estes dígitos são representados em termos das seguintes características: (1) mfeat-fou: 76 coeficientes de Fourier da forma dos caracteres, (2) mfeat-fac: 216 profile correlations, (3) mfeat-kar: 64 coeficientes Karhunen-Love, (4) mfeat-pix: 240 médias de pixel em janelas 2 x 3, (5) mfeat-zer: 47 Zernike moments, (6) mfeat-mor: 6 características morfológicas.

Os três algoritmos de agrupamento (SOM em lote baseado em uma única tabela de dissimilaridade, SOM em lote baseado em múltiplas tabelas de dissimilaridade com ponderação local e sua variante com ponderação global) foram aplicados às matrizes de dissimilaridade representando esta base de dados. No caso do SOM em lote original há somente uma matriz disponível, enquanto que, para os demais estão disponíveis múltiplas matrizes de dissimilaridade. Cada algoritmo foi executado 30 vezes e o melhor resultado foi selecionado de acordo com o critério de adequação. A topologia selecionada para o mapa nesta base de dados é formada por três linhas e dez colunas (3x10) totalizando 30 grupos. O número de iterações escolhido foi de 30 ($N_{iter}=30$). Os experimentos de cada algoritmo foram executados com quatro valores diferentes para $T_{max}$: 8, 9, 12 e 20. Os valores de $T_{min}$ correspondentes foram fixados no valor de 0,3.

\subsubsection{Discussão dos Resultados}

A tabela \ref{mfeat_index} mostra os valores obtidos para os índices $CR$, $F-measure$ e $OERC$ em todos os três algoritmos considerando diferentes valores de $T_{max}$. Em cada linha dessa tabela, pode-se observar os valores dos índices para cada um dos diferentes valores de $T_{max}$. Para esta base, o melhor desempenho global foi apresentado pelos algoritmos AB-SOM com ponderação global and AB-SOM com ponderação local, nesta ordem. O SOM em lote original obteve o pior desempenho global nos índices.

A tabela \ref{mfeat_matrices} mostra o resultado final dos pesos que medem a influência de cada matriz sobre a formação dos grupos. Nesta tabela pode-se observar quais matrizes tiveram maior e menor relevância geral para cada um dos algoritmos para o caso em que o valor de $T_{max} = 9$. A matriz 2 apresentou o peso com maior valor para o algoritmo AB-SOM com ponderação local, indicando maior influência na formação dos grupos durante a execução deste algoritmo. Para o algoritmo AB-SOM com ponderação global, o mesmo comportamento pode ser observado pela matriz 7. Em ambos os algoritmos a matriz menos relevante foi a matriz 3.

\begin{table}[h!]
\begin{center}
\caption{Base Multiple Features: índices $CR$, $F-measure$ e $OERC$} \label{mfeat_index}
\begin{tabular}{|c|c|c|c|c|c|c|} \hline
 Indexes & $T_{max}$ & B-SOM & AB-SOM & global AB-SOM \\ \hline
\multirow{4}{1.8cm}{$CR$} & 8 & 0.5401 & 0.5793 & 0.6259 \\
 & 9 & 0.5364 & 0.6195 & 0.5873 \\ 
 & 12 & 0.5176 & 0.6020 & 0.6221 \\ 
 & 20 & 0.5315 & 0.5756 & 0.6263 \\ \hline
\multirow{4}{1.8cm}{$F-measure$} & 8 & 0.6517 & 0.7001 & 0.7280 \\
 & 9 & 0.6460 & 0.7082 & 0.6809 \\
 & 12 & 0.6216 & 0.7005 & 0.7201 \\
 & 20 & 0.6571 & 0.6733 & 0.7169 \\ \hline
\multirow{4}{1.8cm}{$OERC$} & 8 & 20.00\% & 15.50\% & 8.55\% \\ 
 & 9 & 21.70\% & 9.90\% & 7.70\% \\ 
 & 12 & 28.85\% & 13.15\% & 7.25\% \\ 
 & 20 & 19.30\% & 12.00\% & 7.75\% \\ \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[h!]
\caption{Base Multiple Features: Matrizes $T_{max} = 9$} \label{mfeat_matrices}
\begin{center}
\begin{tabular}{|c|c|c|}
\hline
Model & Most important matrix & Less important matrix \\ \hline
AB-SOM & 4 & 2\\ \hline
global AB-SOM &  & \\ \hline
\end{tabular}
\end{center}
\end{table}